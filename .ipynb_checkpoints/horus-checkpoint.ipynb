{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.linalg as nl\n",
    "import matplotlib.pyplot as plt\n",
    "import groundTruthLocation as gtl\n",
    "\n",
    "max_time = 0\n",
    "train_files = []\n",
    "for i in range(1, 13):\n",
    "    train_files.append('horusrssi/-15dBm0.1secRssi' + str(i) + '.txt')\n",
    "\n",
    "test_file = 'traceRssi-15dB0.1sec1.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_train_data(file_name):\n",
    "    # File content should be [b_i, rssi]\n",
    "    #                        ..........\n",
    "    # Convert it to dictionary dict[index_beacon] = [rss_1, ..., rssi_n]\n",
    "\n",
    "    beacon_dict = {}\n",
    "    with open(file_name, 'r') as packs:\n",
    "        packs.readline()\n",
    "        for pack in packs:\n",
    "            pack = pack[0: len(pack) - 1]\n",
    "            space_loc = pack.find(' ')\n",
    "            beacon = pack[0: space_loc]\n",
    "            ri = float(pack[space_loc + 1:])\n",
    "\n",
    "            if beacon not in beacon_dict:\n",
    "                beacon_dict[beacon] = [ri]\n",
    "            else:\n",
    "                beacon_dict[beacon].append(ri)\n",
    "\n",
    "    return beacon_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_state_location(file_name = 'standingLocation.csv'):\n",
    "    # Assumption that metric in csv file is inch, multiply by 0.0254 to get meters.\n",
    "\n",
    "    with open(file_name, 'r') as file:\n",
    "        file_len = sum(1 for _ in file)\n",
    "\n",
    "    with open(file_name, 'r') as file:\n",
    "        state_loc = np.zeros((file_len, 2))\n",
    "        for line in file:\n",
    "            line = line[0:(len(line)-1)]\n",
    "            splt = line.split(',')\n",
    "            state_loc[int(splt[0])-1][0] = float(splt[1])\n",
    "            state_loc[int(splt[0])-1][1] = float(splt[2])\n",
    "\n",
    "    return 0.0254 * state_loc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_test_data(file_name):\n",
    "    # file header should be [TimeStamp, Beacon, Rssi]\n",
    "    # convert it to numpy array\n",
    "\n",
    "    with open(file_name, 'r') as file:\n",
    "        file_len = sum(1 for _ in file)\n",
    "\n",
    "    with open(file_name) as file:\n",
    "        file.readline() # remove the header\n",
    "        data = np.zeros((file_len - 1, 3))\n",
    "        for line, i in zip(file, range(file_len - 1)):\n",
    "            line = line[0:(len(line)-1)]\n",
    "            splt = line.split(' ')\n",
    "            data[i][0] = float(splt[0])\n",
    "            data[i][1] = int(splt[1])\n",
    "            data[i][2] = float(splt[2])\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_alpha(beacon_dict, num_beacon = 60):\n",
    "    # Returned alphas should be [alpha_b1, alpha_b2, ..., alpha_bn]\n",
    "    # ssvs => signal strength values\n",
    "\n",
    "    alphas = np.zeros(num_beacon)\n",
    "\n",
    "    for beacon in beacon_dict:\n",
    "        ssvs = np.array(beacon_dict[beacon])\n",
    "        num_ssv = len(ssvs)\n",
    "\n",
    "        shift_vec = np.arange(num_ssv - 1) + 1\n",
    "        ssvs_shift = ssvs[shift_vec]\n",
    "        ssvs_trunc = ssvs[0: len(ssvs) - 1]\n",
    "\n",
    "        sbar = np.mean(ssvs)\n",
    "\n",
    "        sumsq = np.sum((ssvs - sbar) ** 2)\n",
    "        if sumsq == 0:   # Need discussion with subham\n",
    "            r1 = 0\n",
    "        else:\n",
    "            r1 = abs(np.sum((ssvs_shift - sbar) * (ssvs_trunc - sbar))) / sumsq\n",
    "\n",
    "        alphas[int(beacon) - 1] = r1\n",
    "\n",
    "    return alphas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(state_files, num_beacon = 60):\n",
    "    # Get mu and sigma for each state, noted that here it's sigma instead of sigma square.\n",
    "\n",
    "    num_state = len(state_files)\n",
    "    state_map = np.zeros((num_state, num_beacon, 2))  # For beacons not in file, mu = -100, sigma = 1/3.\n",
    "    state_map[:,:,0] = -100\n",
    "    state_map[:,:,1] = 1/3\n",
    "\n",
    "    for file, si in zip(state_files, range(num_state)): # si represents state_index\n",
    "        beacon_dict = convert_train_data(file)\n",
    "        alphas = get_alpha(beacon_dict)   # Alphas => [alpha_b1, alpha_b2, ..., alpha_bn]\n",
    "\n",
    "        for rssis in beacon_dict:  # rssis is beacon number\n",
    "            alpha = alphas[int(rssis)-1]\n",
    "            arr = beacon_dict[rssis]\n",
    "            state_map[si][int(rssis)-1][0] = np.mean(arr)\n",
    "            state_map[si][int(rssis)-1][1] = np.sqrt((1 + alpha) / (1 - alpha)*np.var(arr))\n",
    "\n",
    "            if state_map[si][int(rssis)-1][1] == 0:\n",
    "                state_map[si][int(rssis) - 1][1] = 10 # Need discuss with Subham\n",
    "\n",
    "    return state_map\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_cluster(cluster, num_beacon = 60):\n",
    "    # Convert cluster to [beacon_1_avg_rssi, ..., beacon_n_avg_rssi], 0 for beacons not present\n",
    "\n",
    "    ret = np.zeros(num_beacon)\n",
    "    cnt = np.zeros(num_beacon)\n",
    "\n",
    "    arg = np.argsort(cluster[:,1])\n",
    "    cluster = cluster[arg]\n",
    "\n",
    "    for i in range(len(cluster)):\n",
    "        ret[int(cluster[i][1])-1] += cluster[i][2]\n",
    "        cnt[int(cluster[i][1])-1] += 1\n",
    "\n",
    "    cnt[cnt == 0] = 1.0\n",
    "\n",
    "    return ret / cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_test_data(filename, num_beacon = 60, interval = 10):\n",
    "    # Data should be numpy array\n",
    "    # Return dictionary with d['i'] = [beacon_1_avg_rssi, ..., beacon_n_avg_rssi], i represents state_i\n",
    "\n",
    "    data = convert_test_data(filename)\n",
    "    num_rows = data.shape[0]\n",
    "    global max_time\n",
    "    max_time = data[num_rows-1][0]\n",
    "\n",
    "    num_cluster = int(max_time / interval)\n",
    "\n",
    "    start_index = [0]\n",
    "    d = {}\n",
    "\n",
    "    for i in range(1, num_cluster + 1):\n",
    "        thred = interval * i\n",
    "        index = np.searchsorted(data[:,0], thred)\n",
    "        start_index.append(index)\n",
    "\n",
    "    for i in range(len(start_index) - 1):\n",
    "        cluster = data[start_index[i]:start_index[i+1]]\n",
    "        d[i] = process_cluster(cluster)\n",
    "\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(state_map, test_rssi, state_loc, index):   #Discuss with Subham about one hot condition\n",
    "    # return state index with max liklihood\n",
    "    # state_map => (state, beacon, (mu, sigma))\n",
    "    # state_loc => (state, (x, y))\n",
    "    # test_rssi => [avg_rssi]\n",
    "\n",
    "    probs = []\n",
    "\n",
    "    for i in range(state_map.shape[0]):\n",
    "        map_mu = state_map[i][:, 0]\n",
    "        map_sigma = state_map[i][:, 1]\n",
    "\n",
    "        sum_log = - np.sum(np.square(test_rssi - map_mu) / (2 * map_sigma ** 2)) - \\\n",
    "                  np.sum(np.log(map_sigma))\n",
    "\n",
    "        probs.append(sum_log)\n",
    "\n",
    "\n",
    "    probs = np.asarray(probs).reshape(state_map.shape[0], 1)\n",
    "    len_probs = len(probs)\n",
    "    norm_probs = np.zeros(len_probs).reshape(state_map.shape[0], 1)\n",
    "\n",
    "    for i in range(len_probs):\n",
    "        if np.any(probs - probs[i] > 50):\n",
    "            norm_probs[i] = 0\n",
    "        else:\n",
    "            norm_probs[i] = 1 / (np.sum(np.exp(probs - probs[i])))\n",
    "\n",
    "    res = np.sum(norm_probs * state_loc, axis = 0)\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ignore this function\n",
    "def ss_compensator(prev_state, test_file, state_loc, state_map, thred = 2, d = 0.05, N = 6):\n",
    "    # thred => max distance per second\n",
    "    # prev_state, pred_state => numpy (x, y) in meter metric\n",
    "    # d => perturbation fraction\n",
    "\n",
    "    pred_state = np.array([])\n",
    "    min_dist = 0\n",
    "    final_pert = -1\n",
    "    test_rssi = process_test(test_file, 2)\n",
    "    max_index = np.argmax(test_rssi)\n",
    "\n",
    "    for pert in [-0.05, 0, 0.05]:\n",
    "        pert_arr = np.zeros(len(test_rssi))\n",
    "        pert_arr[max_index] = pert\n",
    "\n",
    "        cur_pred = test(state_map, test_rssi + pert_arr, state_loc)\n",
    "        cur_dist = nl.norm(prev_state - cur_pred)\n",
    "\n",
    "        if final_pert == -1 or min_dist > cur_dist:\n",
    "            final_pert = pert\n",
    "            pred_state = cur_pred\n",
    "            min_dist = cur_dist\n",
    "\n",
    "    return pred_state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    state_loc = get_state_location()\n",
    "    state_map = train(train_files)\n",
    "\n",
    "    d = cluster_test_data(test_file)\n",
    "\n",
    "    pred_loc = np.zeros((len(d), 2)) # This is the final prediction\n",
    "\n",
    "    for index in d:\n",
    "        res = test(state_map, d[index], state_loc, index)\n",
    "        pred_loc[index-1][0] = res[0]\n",
    "        pred_loc[index-1][1] = res[1]\n",
    "\n",
    "    global max_time\n",
    "    trueLoc = np.zeros((int(max_time / 10), 2))\n",
    "    for i in range(int(max_time / 10)):\n",
    "        cur = gtl.findActualLocation(startTime=10*(i), endTime=10*(i+1), stopTime=10, maxTime=max_time)\n",
    "        trueLoc[i][0], trueLoc[i][1] = cur[0], cur[1]\n",
    "\n",
    "    #print(np.linalg.norm(pred_loc - trueLoc, axis = 1))\n",
    "    #plt.plot(np.arange(int(max_time / 10)), abs(np.linalg.norm(pred_loc - trueLoc, axis = 1)))\n",
    "    #plt.show()\n",
    "\n",
    "    '''print(state_map[0])\n",
    "\n",
    "    print('================\\n')\n",
    "\n",
    "    print(state_map[1])\n",
    "\n",
    "    print('================\\n')\n",
    "\n",
    "    print(d[1])'''\n",
    "\n",
    "\n",
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
