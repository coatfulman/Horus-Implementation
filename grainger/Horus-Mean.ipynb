{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.linalg as nl\n",
    "import matplotlib.pyplot as plt\n",
    "import groundTruthLocation as gtl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_train_data(file_name):\n",
    "    # File content should be [b_i, rssi]\n",
    "    #                        ..........\n",
    "    # Convert it to dictionary dict[index_beacon] = [rss_1, ..., rssi_n]\n",
    "\n",
    "    beacon_dict = {}\n",
    "    with open(file_name, 'r') as packs:\n",
    "        packs.readline()\n",
    "        for pack in packs:\n",
    "            pack = pack[0: len(pack) - 1]\n",
    "            space_loc = pack.find(' ')\n",
    "            beacon = pack[0: space_loc]\n",
    "            ri = float(pack[space_loc + 1:])\n",
    "\n",
    "            if beacon not in beacon_dict:\n",
    "                beacon_dict[beacon] = [ri]\n",
    "            else:\n",
    "                beacon_dict[beacon].append(ri)\n",
    "\n",
    "    return beacon_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_state_location(file_name = 'standingLocation.csv'):\n",
    "    # Assumption that metric in csv file is inch, multiply by 0.0254 to get meters.\n",
    "    # Return state_loc[i][x,y], i is the i_th state, starting from 0.\n",
    "    \n",
    "    with open(file_name, 'r') as file:\n",
    "        file_len = sum(1 for _ in file)\n",
    "\n",
    "    with open(file_name, 'r') as file:\n",
    "        state_loc = np.zeros((file_len, 2))\n",
    "        for line in file:\n",
    "            line = line[0:(len(line)-1)]\n",
    "            splt = line.split(',')\n",
    "            state_loc[int(splt[0])-1][0] = float(splt[1])\n",
    "            state_loc[int(splt[0])-1][1] = float(splt[2])\n",
    "    state_loc[:][0] += 40\n",
    "    state_loc[:][1] += 80\n",
    "    return 0.0254 * state_loc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_test_data(file_name):\n",
    "    # file header should be [TimeStamp, Beacon, Rssi]\n",
    "    # convert it to numpy array\n",
    "\n",
    "    with open(file_name, 'r') as file:\n",
    "        file_len = sum(1 for _ in file)\n",
    "\n",
    "    with open(file_name) as file:\n",
    "        file.readline() # remove the header\n",
    "        data = np.zeros((file_len - 1, 3))\n",
    "        for line, i in zip(file, range(file_len - 1)):\n",
    "            line = line[0:(len(line)-1)]\n",
    "            splt = line.split(' ')\n",
    "            data[i][0] = float(splt[0])\n",
    "            data[i][1] = int(splt[1])\n",
    "            data[i][2] = float(splt[2])\n",
    "\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_alpha(beacon_dict, num_beacon = 60):\n",
    "    # Returned alphas should be [alpha_b1, alpha_b2, ..., alpha_bn]\n",
    "    # ssvs => signal strength values\n",
    "\n",
    "    alphas = np.zeros(num_beacon)\n",
    "\n",
    "    for beacon in beacon_dict:\n",
    "        ssvs = np.array(beacon_dict[beacon])\n",
    "        num_ssv = len(ssvs)\n",
    "\n",
    "        shift_vec = np.arange(num_ssv - 1) + 1\n",
    "        ssvs_shift = ssvs[shift_vec]\n",
    "        ssvs_trunc = ssvs[0: len(ssvs) - 1]\n",
    "\n",
    "        sbar = np.mean(ssvs)\n",
    "\n",
    "        sumsq = np.sum((ssvs - sbar) ** 2)\n",
    "        if sumsq == 0:   # Need discussion with subham\n",
    "            r1 = 0\n",
    "        else:\n",
    "            r1 = abs(np.sum((ssvs_shift - sbar) * (ssvs_trunc - sbar))) / sumsq\n",
    "\n",
    "        alphas[int(beacon) - 1] = r1\n",
    "\n",
    "    return alphas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(state_files, num_beacon = 60):\n",
    "    # Get mu and sigma for each state, noted that here it's sigma instead of sigma square.\n",
    "    # Return state_map[i][mu,sigma]\n",
    "\n",
    "    num_state = len(state_files)\n",
    "    state_map = np.zeros((num_state, num_beacon, 2))  # For beacons not in file, exclude them\n",
    "    state_map[:,:,0] = -100\n",
    "    state_map[:,:,1] = 1/3\n",
    "\n",
    "    for file, si in zip(state_files, range(num_state)): # si represents state_index\n",
    "        beacon_dict = convert_train_data(file)\n",
    "        alphas = get_alpha(beacon_dict)   # Alphas => [alpha_b1, alpha_b2, ..., alpha_bn]\n",
    "\n",
    "        for rssis in beacon_dict:  # rssis is beacon number\n",
    "            alpha = alphas[int(rssis)-1]\n",
    "            arr = beacon_dict[rssis]\n",
    "            state_map[si][int(rssis)-1][0] = np.mean(arr)\n",
    "            state_map[si][int(rssis)-1][1] = np.sqrt((1 + alpha) / (1 - alpha)*np.var(arr))\n",
    "\n",
    "            if state_map[si][int(rssis)-1][1] == 0:\n",
    "                state_map[si][int(rssis) - 1][1] = 15\n",
    "                #state_map[si][int(rssis) - 1][0] = -100  # Subtle!!! Depends on signal strength.\n",
    "\n",
    "    return state_map\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_cluster(cluster, num_beacon = 60):\n",
    "    # Convert cluster to [beacon_1_avg_rssi, ..., beacon_n_avg_rssi], 0 for beacons not present\n",
    "\n",
    "    ret = np.zeros(num_beacon)\n",
    "    cnt = np.zeros(num_beacon)\n",
    "\n",
    "    arg = np.argsort(cluster[:,1])\n",
    "    cluster = cluster[arg]\n",
    "\n",
    "    for i in range(len(cluster)):\n",
    "        ret[int(cluster[i][1])-1] += cluster[i][2]\n",
    "        cnt[int(cluster[i][1])-1] += 1\n",
    "\n",
    "    cnt[cnt == 0] = 1.0\n",
    "\n",
    "    return ret / cnt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_test_data(filename, num_beacon = 60, interval = 10):\n",
    "    # Data should be numpy array\n",
    "    # Return dictionary with d['i'] = [beacon_1_avg_rssi, ..., beacon_n_avg_rssi], i represents state_i\n",
    "\n",
    "    data = convert_test_data(filename)\n",
    "    num_rows = data.shape[0]\n",
    "    max_time = data[num_rows-1][0]\n",
    "\n",
    "    num_cluster = int(max_time / interval)\n",
    "    start_index = [0]\n",
    "    d = {}\n",
    "\n",
    "    for i in range(1, num_cluster + 1):\n",
    "        thred = interval * i\n",
    "        index = np.searchsorted(data[:,0], thred)\n",
    "        start_index.append(index)\n",
    "\n",
    "    for i in range(len(start_index) - 1):\n",
    "        cluster = data[start_index[i]:start_index[i+1]]\n",
    "        d[i] = process_cluster(cluster)\n",
    "\n",
    "    return d, max_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(state_map, test_rssi, state_loc, index, jud):\n",
    "    jud = 1 - jud\n",
    "    # return state index with max liklihood\n",
    "    # state_map => (state, beacon, (mu, sigma))\n",
    "    # state_loc => (state, (x, y))\n",
    "    # test_rssi => [avg_rssi]\n",
    "\n",
    "    probs = []\n",
    "    arg_zero = (abs(test_rssi) > 1.0) * jud\n",
    "\n",
    "    for i in range(state_map.shape[0]):\n",
    "        map_mu = state_map[i][:, 0]\n",
    "        map_sigma = state_map[i][:, 1]\n",
    "\n",
    "        sum_log = - np.sum(arg_zero * np.square(test_rssi - map_mu) / (2 * map_sigma ** 2)) - \\\n",
    "                  np.sum(np.log(map_sigma) * arg_zero)\n",
    "\n",
    "        probs.append(sum_log)\n",
    "    probs = np.asarray(probs).reshape(state_map.shape[0], 1)\n",
    "\n",
    "    len_probs = len(probs)\n",
    "    norm_probs = np.zeros(len_probs).reshape(state_map.shape[0], 1)\n",
    "\n",
    "    for i in range(len_probs):\n",
    "        if np.any(probs - probs[i] > 50):\n",
    "            norm_probs[i] = 0\n",
    "        else:\n",
    "            norm_probs[i] = 1 / (np.sum(np.exp(probs - probs[i])))\n",
    "\n",
    "    res = np.sum(norm_probs * state_loc, axis = 0)\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ss_compensator(prev_state, test_file, state_loc, state_map, thred = 2, d = 0.05, N = 6):\n",
    "    # thred => max distance per second\n",
    "    # prev_state, pred_state => numpy (x, y) in meter metric\n",
    "    # d => perturbation fraction\n",
    "\n",
    "    pred_state = np.array([])\n",
    "    min_dist = 0\n",
    "    final_pert = -1\n",
    "    test_rssi = process_test(test_file, 2)\n",
    "    max_index = np.argmax(test_rssi)\n",
    "\n",
    "    for pert in [-0.05, 0, 0.05]:\n",
    "        pert_arr = np.zeros(len(test_rssi))\n",
    "        pert_arr[max_index] = pert\n",
    "\n",
    "        cur_pred = test(state_map, test_rssi + pert_arr, state_loc)\n",
    "        cur_dist = nl.norm(prev_state - cur_pred)\n",
    "\n",
    "        if final_pert == -1 or min_dist > cur_dist:\n",
    "            final_pert = pert\n",
    "            pred_state = cur_pred\n",
    "            min_dist = cur_dist\n",
    "\n",
    "    return pred_state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(freq, intv):\n",
    "    # with open(\"Beacon Log\", \"a+\") as file:\n",
    "    #     file.writelines('\\n' + str(freq) + ', ' + str(intv) + ': \\n')\n",
    "\n",
    "    train_files = []\n",
    "    for i in range(1, 13):\n",
    "        train_files.append('horusrssi/' + str(freq) + 'dBm' + str(intv) + 'secRssi' + str(i) + '.txt')\n",
    "\n",
    "    test_file = 'traceRssi' + str(freq) + 'dB' + str(intv) + 'sec1.txt'\n",
    "\n",
    "    state_loc = get_state_location()\n",
    "    state_map = train(train_files)\n",
    "\n",
    "    jud = np.zeros(60)\n",
    "\n",
    "    ###################################\n",
    "    if freq == -12 and intv == 1:\n",
    "        iter = np.array([4, 18, 21, 50, 59, 46, 11, 28, 22, 39 ])\n",
    "        jud[iter] = 1\n",
    "                                                                    # Hard code some beacons to ignore.\n",
    "    if freq == -15 and intv == 0.1:\n",
    "        iter = np.array([44, 36, 38, 53])\n",
    "        jud[iter] = 1\n",
    "    ##################################\n",
    "\n",
    "# Whether to ignore some beacons lost in training stage.\n",
    "#     for i in range(12):    \n",
    "#         cur = state_map[i]\n",
    "#         for j in range(60):\n",
    "#             if cur[j][0] == -100:\n",
    "#                 jud[j] = 1\n",
    "                # with open(\"Beacon Log\", \"a+\") as file:\n",
    "                #     file.writelines('State '+str(i+1)+ ', loc: (' + str(state_loc[i][0])+ ', ' + str(state_loc[i][1]) + ') Beacon '+str(j) + '\\n')\n",
    "                # print('State '+str(i+1)+ ', loc: (' + str(state_loc[i][0])+ ', ' + str(state_loc[i][1]) + ') Beacon '+str(j))\n",
    "\n",
    "    d, max_time = cluster_test_data(test_file)\n",
    "    pred_loc = np.zeros((len(d), 2))\n",
    "\n",
    "    for index in d:\n",
    "        res = test(state_map, d[index], state_loc, index, jud)\n",
    "        pred_loc[index-1][0] = res[0]\n",
    "        pred_loc[index-1][1] = res[1]\n",
    "\n",
    "    trueLoc = np.zeros((int(max_time / 10), 2))\n",
    "\n",
    "    for i in range(int(max_time / 10)):\n",
    "        cur = gtl.findActualLocation(startTime=10*(i), endTime=10*(i+1), stopTime=10, maxTime=max_time)\n",
    "        trueLoc[i][0], trueLoc[i][1] = cur[0], cur[1]\n",
    "\n",
    "    valid_x = 1 - (trueLoc[:,0] < 4) - (trueLoc[:,0] > 8)    # X and Y coordinates to ignore\n",
    "    valid_y = trueLoc[:,1] < 4\n",
    "    valid_loc = valid_x * valid_y\n",
    "    errors = valid_loc * np.linalg.norm(pred_loc - trueLoc, axis = 1)\n",
    "    avg_error = np.sum(errors) / np.sum(valid_loc)\n",
    "    \n",
    "    with open(\"g_pred/graingerErrorHorus_trip\"+\"1\" + str(freq) + \"db\" + str(intv) + \"sec\", \"w+\") as file:\n",
    "        for loc in pred_loc:\n",
    "            file.writelines(str(loc[0]) + \",\" + str(loc[1]) + \"\\n\")\n",
    "\n",
    "    # with open(\"Erro Log\", \"a+\") as file:\n",
    "    #     file.writelines('Frequency: ' + str(freq) + ', time interval: ' + str(intv) + ', error: ' + str(avg_error) + '\\n')\n",
    "\n",
    "    print('Frequency: ' + str(freq) + ', time interval: ' + str(intv) + ', error: ' + str(avg_error) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequency: -12, time interval: 0.1, error: 2.985099145309715\n",
      "Frequency: -12, time interval: 0.5, error: 1.61661339848874\n",
      "Frequency: -12, time interval: 1, error: 1.3919047902202877\n",
      "Frequency: -15, time interval: 0.1, error: 2.1620269249054713\n",
      "Frequency: -15, time interval: 0.5, error: 1.8317172273872027\n",
      "Frequency: -15, time interval: 1, error: 2.259498478181672\n",
      "Frequency: -20, time interval: 0.1, error: 1.7436425642493352\n",
      "Frequency: -20, time interval: 0.5, error: 2.2408617624524623\n",
      "Frequency: -20, time interval: 1, error: 2.295916367070272\n"
     ]
    }
   ],
   "source": [
    "freqs = [-12, -15, -20]\n",
    "intvs = [0.1, 0.5, 1]\n",
    "\n",
    "for freq in freqs:\n",
    "    for intv in intvs:\n",
    "        main(freq, intv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
