{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.linalg as nl\n",
    "\n",
    "def turn_to_dict(file_name):\n",
    "    beacon_dict = {}\n",
    "\n",
    "    with open(file_name, 'r') as packs:\n",
    "        for pack in packs:\n",
    "            pack = pack[0: len(pack) - 1]\n",
    "            space_loc = pack.find(' ')\n",
    "            beacon = pack[0: space_loc]\n",
    "            ri = float(pack[space_loc + 1:])\n",
    "\n",
    "            if beacon not in beacon_dict:\n",
    "                beacon_dict[beacon] = [ri]\n",
    "            else:\n",
    "                beacon_dict[beacon].append(ri)\n",
    "\n",
    "    return beacon_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_alpha(beacon_dict):\n",
    "    #ssvs => signal strength values\n",
    "    \n",
    "    num_beacon = len(beacon_dict)\n",
    "    alphas = np.zeros(num_beacon)\n",
    "    \n",
    "    for beacon in beacon_dict:\n",
    "        beacon_index = int(beacon[1:]) - 1\n",
    "        ssvs = np.array(beacon_dict[beacon])\n",
    "        num_ssv = len(ssvs)\n",
    "        \n",
    "        shift_vec = np.arange(num_ssv - 1) + 1\n",
    "        ssvs_shift = ssvs[shift_vec]\n",
    "        ssvs_trunc = ssvs[0: len(ssvs) - 1]\n",
    "    \n",
    "        sbar = np.mean(ssvs)\n",
    "        r1 = abs(np.sum((ssvs_shift - sbar)*(ssvs_trunc - sbar))) / (np.sum((ssvs - sbar) ** 2))\n",
    "        alphas[beacon_index] = r1\n",
    "        \n",
    "    return alphas\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(state_files, num_beacon):\n",
    "    # Currently fake data\n",
    "    # alpha => [alpha_b1, alpha_b2, ..., alpha_bn]\n",
    "\n",
    "    num_state = len(state_files)\n",
    "    state_map = np.zeros((num_state, num_beacon, 2))\n",
    "    \n",
    "    for file, si in zip(state_files, range(num_state)):\n",
    "        beacon_dict = turn_to_dict(file)\n",
    "        alphas = get_alpha(beacon_dict)\n",
    "      \n",
    "        for rssis in beacon_dict:\n",
    "            alpha = alphas[int(rssis[1:])-1]\n",
    "            arr = beacon_dict[rssis]\n",
    "            state_map[si][int(rssis[1:])-1][0] = np.mean(arr)\n",
    "            state_map[si][int(rssis[1:])-1][1] = np.sqrt(((1 + alpha) / (1 - alpha))*np.var(arr))\n",
    "\n",
    "    return state_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_test(test_name, num_beacon):\n",
    "    # Turn original file to numpy array with [avg_b1_rssi, avg_b2_rssi, ..., avg_bn_rssi]\n",
    "\n",
    "    beacon_dict = turn_to_dict(test_name)\n",
    "    avg = np.zeros(num_beacon)\n",
    "\n",
    "    for bi in beacon_dict:\n",
    "        index = int(bi[1:])\n",
    "        avg[index - 1] = np.mean(beacon_dict[bi])\n",
    "\n",
    "    return avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(state_map, test_rssi, state_loc):\n",
    "    # return state index with max liklihood\n",
    "    # state_map => (state, beacon, (mu, sigma))\n",
    "    # state_loc => (state, (x, y))\n",
    "    # test_rssi => [avg_rssi]\n",
    "\n",
    "    probs = []\n",
    "\n",
    "    for i in range(state_map.shape[0]):\n",
    "        map_mu = state_map[i][:, 0]\n",
    "        map_sigma = state_map[i][:, 1]\n",
    "        sum_log = - np.sum(np.square(test_rssi - map_mu) / (2 * map_sigma ** 2)) - \\\n",
    "                  np.sum(np.log(map_sigma))\n",
    "        probs.append(1 / np.exp(-sum_log))\n",
    "        \n",
    "    probs = np.asarray(probs).reshape(state_map.shape[0], 1)\n",
    "    probs = probs / np.sum(probs)\n",
    "    res = np.sum(probs * state_loc, axis = 0)\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ss_compensator(prev_state, test_file, state_loc, state_map, thred = 2, d = 0.05):\n",
    "    # thred => max distance per second\n",
    "    # prev_state, pred_state => numpy (x, y) in meter metric\n",
    "    # d => perturbation fraction\n",
    "    \n",
    "    pred_state = np.array([])\n",
    "    min_dist = 0\n",
    "    final_pert = -1\n",
    "    test_rssi = process_test(test_file, 2)\n",
    "    max_index = np.argmax(test_rssi)\n",
    "    \n",
    "    for pert in [-0.05, 0, 0.05]:\n",
    "        pert_arr = np.zeros(len(test_rssi))\n",
    "        pert_arr[max_index] = pert\n",
    "       \n",
    "        cur_pred = test(state_map, test_rssi + pert_arr, state_loc)\n",
    "        cur_dist = nl.norm(prev_state - cur_pred)\n",
    "        \n",
    "        if final_pert == -1 or min_dist > cur_dist:\n",
    "            final_pert = pert\n",
    "            pred_state = cur_pred\n",
    "            min_dist = cur_dist\n",
    "    \n",
    "    print(\"pert: \" + str(final_pert))\n",
    "     \n",
    "    return pred_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.01976617 -0.36615778]\n",
      "[-0.06976617 -0.36615778]\n",
      "[-0.01976617 -0.36615778]\n",
      "[ 0.03023383 -0.36615778]\n",
      "pert: 0\n",
      "[1.22400118 0.94410251]\n",
      "[1.17400118 0.94410251]\n",
      "[1.22400118 0.94410251]\n",
      "[1.27400118 0.94410251]\n",
      "pert: 0.05\n",
      "[0.         1.28918069] [0.         1.65724603]\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    state_loc = np.array([[0, 1], [0, 2]])\n",
    "    state_files = ['s1', 's2']\n",
    "    state_map = train(state_files, 2)\n",
    "    res1 = ss_compensator(state_loc[0], 's1', state_loc, state_map)\n",
    "    res2 = ss_compensator(state_loc[1], 's2', state_loc, state_map)\n",
    "   \n",
    "    print(res1, res2)\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
